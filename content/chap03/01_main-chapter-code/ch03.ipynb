{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Attention Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import lightning as L\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "L.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Rodrigo W Pisaia\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.10.16\n",
      "IPython version      : 8.30.0\n",
      "\n",
      "pandas    : 2.2.3\n",
      "torch     : 2.6.0+cu126\n",
      "numpy     : 2.1.3\n",
      "lightning : 2.5.0.post0\n",
      "matplotlib: 3.10.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a \"Rodrigo W Pisaia\" --iversions --python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1) Simplified self-attention\n",
    "* 2) Self-attention\n",
    "* 3) Causal attention\n",
    "* 4) Multi-head Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![causal_self_attention](../images/image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RWP\\AppData\\Local\\Temp\\ipykernel_7504\\2096973130.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.dot(torch.tensor(inputs[1]).detach(),torch.tensor(inputs[1]).detach()) # the self weight doesn't have value 1, because it is basically the square\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.4950)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(torch.tensor(inputs[1]).detach(),torch.tensor(inputs[1]).detach()) # the self weight doesn't have value 1, because it is basically the square\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([0.4300, 0.1500, 0.8900])\n"
     ]
    }
   ],
   "source": [
    "# calculate attention values with journey\n",
    "query = inputs[1] # [0.55, 0.87, 0.66]\n",
    "attn_scores_2 = torch.empty(inputs.shape[0]) # 6\n",
    "for i, x_in in enumerate(inputs):\n",
    "    print(i, x_in)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, x_in in enumerate(inputs):\n",
    "    attn_scores_2[i] = torch.dot(x_in, query)\n",
    "attn_scores_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9544\n",
      "tensor(0.9544)\n",
      "tensor(0.9544)\n"
     ]
    }
   ],
   "source": [
    "# internaly it will be a matrix multiplication\n",
    "res = 0.\n",
    "for idx, element in enumerate(inputs[0]):\n",
    "    res += inputs[0][idx] * query[idx]\n",
    "\n",
    "print(0.43*0.55+0.15*0.87+0.89*0.66) # explicit calculation of dot product\n",
    "print(res)\n",
    "print(torch.dot(inputs[0], query)) # dot product "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Attention Weights](../images/attention_weights.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
      "tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "attn_weights_2_tmp = attn_scores_2/torch.sum(attn_scores_2)\n",
    "print(attn_weights_2_tmp)\n",
    "print(torch.sum(attn_weights_2_tmp)) # the sum of normalized attention weights is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "def softmax_naive(x):\n",
    "    \n",
    "    return torch.exp(x) / torch.exp(x).sum(dim=0)\n",
    "    # return torch.exp(x)/torch.sum(torch.exp(x))\n",
    "\n",
    "attn_weights_2_naive = softmax_naive(attn_scores_2)\n",
    "\n",
    "print(\"Attention weights:\", attn_weights_2_naive)\n",
    "print(\"Sum:\", attn_weights_2_naive.sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
